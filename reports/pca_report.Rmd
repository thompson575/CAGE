---
title: 'CAGE: PCA of 1000 Probes'
author: "John Thompson"
date: "21st March 2023"
output: 
    prettydoc::html_pretty:
      theme: architect
---

```{r setup, include=FALSE}
# --- theme architect requires  R package prettydoc
library(tidyverse)
library(glue)
library(fs)

# --- display functions
code  <- "C:/Projects/RCourse/Masterclass/CAGE/code"
source(path(code, "display_functions.R"))

# --- read data from cache
cache <- "C:/Projects/RCourse/Masterclass/CAGE/data/cache"

patientDF     <- readRDS(path(cache, "patients.rds"))
trainDF       <- readRDS(path(cache, "training.rds"))
validDF       <- readRDS(path(cache, "validation.rds"))
vpca          <- readRDS(path(cache, "train_vpca.rds"))
vScoreTrainDF <- readRDS(path(cache, "train_vpca_scores.rds"))
vScoreValidDF <- readRDS(path(cache, "valid_vpca_scores.rds"))
cpca          <- readRDS(path(cache, "train_cpca.rds"))
cScoreTrainDF <- readRDS(path(cache, "train_cpca_scores.rds"))
cScoreValidDF <- readRDS(path(cache, "valid_cpca_scores.rds"))

# --- chunk options
knitr::opts_chunk$set(echo = FALSE, 
                      fig.align = "center",
                      message=FALSE)

# --- plotting theme
theme_set(theme_classic())
```

## CAGE

CAGE (Classification After Gene Expression) explores ways of selecting features from a gene expression study for use in patient classification. In particular, it investigates the pros and cons of basing the classification on the principal components of the gene expression.

## 1000 Probe Subset of the Data

A random sample of 1000 probes was used to create a subset of the data that would enable quicker development of the code. The training data consist of the 1000 probes measured on the patients from AEGIS-1 and the validation data consist of the same probes measured on the patients from AEGIS-2.

This report looks at the principal component analysis (PCA) of the training data.

## Unscaled Principal Components

Figure 1 shows the percentage of the variance captured by each of the unscaled principal components.

```{r}
plot_eigenvalues(vpca$sdev[1:50], pct = TRUE ) +
  ggtitle("Fig 1: Percent Explained by the Unscaled PCs")
```

A table of the cumulative percentage of the variance explained by the first 20 PCs shows that the first three principal components capture over 50% of the variance in the expressions.
```{r}
tibble( pc = 1:375,
        sd = vpca$sdev) %>%
  mutate( var = sd * sd,
          pct = round(100 * var / sum(var), 1),
          var = round(var, 1),
          cumpct = cumsum(pct)) %>%
  select( pc, var, pct, cumpct) %>%
  slice(1:20) %>%
  print()
```

Figure 2 shows the principal component scores of the patients in the training data (AEGIS-1) for the first 5 PCs separated by diagnosis.

```{r}
glue( "PC{1:5}" ) %>%
  boxplot_features( vScoreTrainDF %>%
                      left_join(patientDF, by = "id")) +
  labs(title = "Fig 2: Training data: Unscaled PCA Scores by diagnosis",
       y     = "Score",
       x     = "Principal Component")
```

Figure 3 shows the principal component scores of the patients in the validation data (AEGIS-2) for the first 5 PCs as derived from the training data.

```{r}
glue( "PC{1:5}" ) %>%
  boxplot_features( vScoreValidDF %>%
                      left_join(patientDF, by = "id")) +
  labs(title = "Fig 3: Validation data: Unscaled PCA Scores by diagnosis",
       y     = "Score",
       x     = "Principal Component")

```

## Scaled Principal Components

Figure 4 shows the percentage of the variance captured by each of the scaled principal components.

```{r}
plot_eigenvalues(cpca$sdev[1:50], pct = TRUE ) +
  ggtitle("Fig 4: Percent Explained by the Scaled PCs")
```

A table of the cumulative percentage of the variance explained by the first 20 PCs shows that 5 scaled principal components are needed to capture over 50% of the variance.
```{r}
tibble( pc = 1:375,
        sd = cpca$sdev) %>%
  mutate( var = sd * sd,
          pct = round(100 * var / sum(var), 1),
          var = round(var, 1),
          cumpct = cumsum(pct)) %>%
  select( pc, var, pct, cumpct) %>%
  slice(1:20) %>%
  print()
  
```

Figure 5 shows the principal component scores of the patients in the training data (AEGIS-1) for the first 5 scaled PCs separated by diagnosis.

```{r}
glue( "PC{1:5}" ) %>%
  boxplot_features( cScoreTrainDF %>%
                      left_join(patientDF, by = "id")) +
  labs(title = "Fig 5: Training data: Scaled PCA Scores by diagnosis",
       y     = "Score",
       x     = "Principal Component")
```

Figure 6 shows the principal component scores of the patients in the validation data (AEGIS-2) for the first 5 PCs as derived from the training data.

```{r}
glue( "PC{1:5}" ) %>%
  boxplot_features( cScoreValidDF %>%
                      left_join(patientDF, by = "id")) +
  labs(title = "Fig 6: Validation data: Scaled PCA Scores by diagnosis",
       y     = "Score",
       x     = "Principal Component")

```

## Conclusions

The unscaled and scaled PCAs appear to be quite similar. This is not surprising given that the expressions are normalised within subject and as a result the distributions of the expressions within probes are relatively similar.

It is not clear which analysis will be most stable, or which will better capture the differences between benign disease and cancer.

## Issues

* PCA is sensitive to outliers and there are some quite extreme values in the data. Perhaps the scaled analysis will be less sensitive to outliers.  

* PCs are linear and independent. The relationships of the probes with diagnosis might well be non-linear and interacting.